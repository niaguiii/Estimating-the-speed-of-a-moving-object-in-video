"""
ç®€åŒ–ç‰ˆä¸»ç¨‹åº - ä½¿ç”¨OpenCVå†…ç½®åŠŸèƒ½å®žçŽ°ç‰©ä½“æ£€æµ‹å’Œè¿½è¸ª
é¿å…ä¾èµ–problematicçš„ultralyticsåŒ…
"""
import cv2
import numpy as np
import os
import argparse
import sys
import urllib.request

class OpenCVObjectDetector:
    def __init__(self):
        """åˆå§‹åŒ–OpenCV DNNæ£€æµ‹å™¨"""
        self.net = None
        self.output_layers = None
        self.classes = []
        
        # ä¸‹è½½å¹¶åŠ è½½YOLOv3æ¨¡åž‹ï¼ˆOpenCVå…¼å®¹ç‰ˆæœ¬ï¼‰
        self.setup_yolo_model()
        
    def setup_yolo_model(self):
        """è®¾ç½®YOLOæ¨¡åž‹ - æ”¯æŒYOLOv8/YOLOv5 ONNXå’ŒYOLOv3"""
        # ä¼˜å…ˆå°è¯•YOLOv8/YOLOv5 ONNXæ¨¡åž‹
        onnx_model = 'models/yolov8n.onnx'
        if os.path.exists(onnx_model):
            model_files = {
                'onnx': onnx_model,
                'names': 'models/coco.names'
            }
            self.model_type = 'onnx'
        else:
            # å›žé€€åˆ°YOLOv3
            model_files = {
                'weights': 'models/yolov3.weights',
                'config': 'models/yolov3.cfg',
                'names': 'models/coco.names'
            }
            self.model_type = 'darknet'
        
        # ç¡®ä¿modelsç›®å½•å­˜åœ¨
        os.makedirs('models', exist_ok=True)
        
        # æ£€æŸ¥æ¨¡åž‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æžœä¸å­˜åœ¨åˆ™ä¸‹è½½
        for file_type, filename in model_files.items():
            if not os.path.exists(filename):
                print(f"æ­£åœ¨ä¸‹è½½ {filename}...")
                self.download_model_file(file_type, filename)
        
        try:
            if self.model_type == 'onnx':
                # åŠ è½½ONNXæ¨¡åž‹ (YOLOv8/YOLOv5)
                self.net = cv2.dnn.readNetFromONNX(model_files['onnx'])
                print("âœ… YOLOv8/YOLOv5 ONNXæ¨¡åž‹åŠ è½½æˆåŠŸ")
                
                # è®¾ç½®æŽ¨ç†åŽç«¯ï¼ˆå¯é€‰ï¼Œæé«˜æ€§èƒ½ï¼‰
                self.net.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV)
                self.net.setPreferableTarget(cv2.dnn.DNN_TARGET_CPU)
            else:
                # åŠ è½½Darknetæ¨¡åž‹ (YOLOv3)
                self.net = cv2.dnn.readNet(model_files['weights'], model_files['config'])
                # èŽ·å–è¾“å‡ºå±‚
                layer_names = self.net.getLayerNames()
                self.output_layers = [layer_names[i - 1] for i in self.net.getUnconnectedOutLayers()]
                print("âœ… YOLOv3 Darknetæ¨¡åž‹åŠ è½½æˆåŠŸ")
            
            # åŠ è½½ç±»åˆ«åç§°
            with open(model_files['names'], 'r') as f:
                self.classes = [line.strip() for line in f.readlines()]
            
            print(f"ðŸ“ åŠ è½½äº† {len(self.classes)} ä¸ªç‰©ä½“ç±»åˆ«")
            
        except Exception as e:
            print(f"âŒ YOLOæ¨¡åž‹åŠ è½½å¤±è´¥: {e}")
            print("å¯èƒ½åŽŸå› ï¼šæ¨¡åž‹æ–‡ä»¶æœªä¸‹è½½æˆ–æŸå")
            print("æ­£åœ¨åˆ‡æ¢åˆ°å¤‡ç”¨æ£€æµ‹æ–¹æ³•...")
            self.setup_fallback_detector()
    
    def download_model_file(self, file_type, filename):
        """ä¸‹è½½æ¨¡åž‹æ–‡ä»¶"""
        urls = {
            'weights': 'https://pjreddie.com/media/files/yolov3.weights',
            'config': 'https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg',
            'names': 'https://raw.githubusercontent.com/pjreddie/darknet/master/data/coco.names'
        }
        
        try:
            urllib.request.urlretrieve(urls[file_type], filename)
            print(f"âœ… {filename} ä¸‹è½½å®Œæˆ")
        except Exception as e:
            print(f"âŒ {filename} ä¸‹è½½å¤±è´¥: {e}")
            if file_type == 'names':
                # å¦‚æžœä¸‹è½½å¤±è´¥ï¼Œåˆ›å»ºåŸºç¡€çš„ç±»åˆ«æ–‡ä»¶
                self.create_basic_coco_names(filename)
    
    def create_basic_coco_names(self, filename):
        """åˆ›å»ºåŸºç¡€çš„COCOç±»åˆ«æ–‡ä»¶"""
        basic_classes = [
            'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck',
            'boat', 'traffic light', 'fire hydrant', 'stop sign', 'parking meter', 'bench'
        ]
        
        with open(filename, 'w') as f:
            for class_name in basic_classes:
                f.write(class_name + '\n')
        
        print(f"âœ… åˆ›å»ºåŸºç¡€ {filename}")
    
    def setup_fallback_detector(self):
        """è®¾ç½®å¤‡ç”¨æ£€æµ‹å™¨ï¼ˆHaarçº§è”ï¼‰"""
        try:
            # ä½¿ç”¨OpenCVå†…ç½®çš„äººè„¸æ£€æµ‹å™¨ä½œä¸ºç¤ºä¾‹
            self.cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
            self.classes = ['face']
            self.net = None  # æ ‡è®°ä½¿ç”¨å¤‡ç”¨æ–¹æ³•
            print("âœ… å¤‡ç”¨æ£€æµ‹å™¨åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ å¤‡ç”¨æ£€æµ‹å™¨åŠ è½½å¤±è´¥: {e}")
    
    def detect_objects(self, frame):
        """æ£€æµ‹ç‰©ä½“"""
        if self.net is not None:
            return self.detect_with_yolo(frame)
        else:
            return self.detect_with_cascade(frame)
    
    def detect_with_yolo(self, frame):
        """ä½¿ç”¨YOLOæ£€æµ‹ - æ”¯æŒONNXå’ŒDarknetæ ¼å¼"""
        height, width = frame.shape[:2]
        
        if self.model_type == 'onnx':
            # YOLOv8/YOLOv5 ONNXæ ¼å¼
            blob = cv2.dnn.blobFromImage(frame, 1/255.0, (640, 640), swapRB=True, crop=False)
            self.net.setInput(blob)
            outputs = self.net.forward()
            return self.parse_onnx_output(outputs, width, height)
        else:
            # YOLOv3 Darknetæ ¼å¼
            blob = cv2.dnn.blobFromImage(frame, 0.00392, (416, 416), (0, 0, 0), True, crop=False)
            self.net.setInput(blob)
            outputs = self.net.forward(self.output_layers)
            return self.parse_darknet_output(outputs, width, height)
    
    def parse_onnx_output(self, outputs, width, height):
        """è§£æžONNXæ¨¡åž‹è¾“å‡º (YOLOv8/YOLOv5æ ¼å¼)"""
        output = outputs[0]
        
        # YOLOv8è¾“å‡ºæ ¼å¼: [1, 84, 8400] -> [classes + xywh + conf]
        if len(output.shape) == 3:
            output = output[0]  # ç§»é™¤batchç»´åº¦
        
        # è½¬ç½®: [84, 8400] -> [8400, 84]
        output = output.transpose()
        
        boxes = []
        confidences = []
        class_ids = []
        
        # YOLOv8æ ¼å¼: [cx, cy, w, h, class1_conf, class2_conf, ...]
        # æ²¡æœ‰å•ç‹¬çš„objectnessåˆ†æ•°ï¼Œç±»åˆ«ç½®ä¿¡åº¦å°±æ˜¯æœ€ç»ˆç½®ä¿¡åº¦
        for row in output:
            # æå–ç±»åˆ«åˆ†æ•° (ç¬¬5åˆ—å¼€å§‹æ˜¯80ä¸ªç±»åˆ«çš„åˆ†æ•°)
            classes_scores = row[4:84]  # COCOæœ‰80ä¸ªç±»åˆ«
            class_id = np.argmax(classes_scores)
            max_class_confidence = classes_scores[class_id]
            
            # æ£€æŸ¥ç½®ä¿¡åº¦èŒƒå›´æ˜¯å¦æ­£å¸¸ï¼ˆåº”è¯¥åœ¨0-1ä¹‹é—´ï¼‰
            if max_class_confidence > 1.0:
                # å¦‚æžœç½®ä¿¡åº¦å¤§äºŽ1ï¼Œå¯èƒ½éœ€è¦sigmoidå½’ä¸€åŒ–
                max_class_confidence = 1.0 / (1.0 + np.exp(-max_class_confidence))
            
            # ä½¿ç”¨åˆç†çš„é˜ˆå€¼
            if max_class_confidence >= 0.5:  # ä½¿ç”¨0.5ä½œä¸ºé˜ˆå€¼
                # æå–è¾¹ç•Œæ¡† (center_x, center_y, width, height)
                cx, cy, w, h = row[0:4]
                
                # è½¬æ¢ä¸ºåƒç´ åæ ‡
                cx = cx * width / 640
                cy = cy * height / 640
                w = w * width / 640
                h = h * height / 640
                
                # è½¬æ¢ä¸ºå·¦ä¸Šè§’åæ ‡
                x = int(cx - w / 2)
                y = int(cy - h / 2)
                w = int(w)
                h = int(h)
                
                # ç¡®ä¿è¾¹ç•Œæ¡†åœ¨å›¾åƒèŒƒå›´å†…
                x = max(0, x)
                y = max(0, y)
                w = min(w, width - x)
                h = min(h, height - y)
                
                if w > 10 and h > 10:  # ç¡®ä¿è¾¹ç•Œæ¡†æœ‰æ•ˆä¸”ä¸å¤ªå°
                    boxes.append([x, y, w, h])
                    confidences.append(float(max_class_confidence))
                    class_ids.append(class_id)
        
        return self.apply_nms(boxes, confidences, class_ids)
    
    def parse_darknet_output(self, outputs, width, height):
        """è§£æžDarknetæ¨¡åž‹è¾“å‡º (YOLOv3æ ¼å¼)"""
        boxes = []
        confidences = []
        class_ids = []
        
        for output in outputs:
            for detection in output:
                scores = detection[5:]
                class_id = np.argmax(scores)
                confidence = scores[class_id]
                
                if confidence > 0.25:  # é™ä½Žé˜ˆå€¼ä»¥æé«˜æ£€æµ‹çŽ‡
                    center_x = int(detection[0] * width)
                    center_y = int(detection[1] * height)
                    w = int(detection[2] * width)
                    h = int(detection[3] * height)
                    
                    x = int(center_x - w / 2)
                    y = int(center_y - h / 2)
                    
                    boxes.append([x, y, w, h])
                    confidences.append(float(confidence))
                    class_ids.append(class_id)
        
        return self.apply_nms(boxes, confidences, class_ids)
    
    def apply_nms(self, boxes, confidences, class_ids):
        """åº”ç”¨éžæžå¤§å€¼æŠ‘åˆ¶å¹¶è¿”å›žæ£€æµ‹ç»“æžœ"""
        # éžæžå¤§å€¼æŠ‘åˆ¶ - ä½¿ç”¨åˆç†çš„ç½®ä¿¡åº¦é˜ˆå€¼
        indices = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)
        
        detections = []
        if len(indices) > 0:
            for i in indices.flatten():
                detections.append({
                    'bbox': boxes[i],
                    'confidence': confidences[i],
                    'class_id': class_ids[i],
                    'class_name': self.classes[class_ids[i]] if class_ids[i] < len(self.classes) else 'unknown'
                })
        
        return detections
    
    def detect_with_cascade(self, frame):
        """ä½¿ç”¨çº§è”åˆ†ç±»å™¨æ£€æµ‹"""
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = self.cascade.detectMultiScale(gray, 1.1, 4)
        
        detections = []
        for (x, y, w, h) in faces:
            detections.append({
                'bbox': [x, y, w, h],
                'confidence': 0.8,
                'class_id': 0,
                'class_name': 'face'
            })
        
        return detections

class SimpleTracker:
    def __init__(self):
        """ç®€å•çš„ç‰©ä½“è¿½è¸ªå™¨"""
        self.tracks = []
        self.next_id = 1
        self.max_disappeared = 10
    
    def update(self, detections):
        """æ›´æ–°è¿½è¸ª"""
        if len(self.tracks) == 0:
            # åˆå§‹åŒ–è¿½è¸ª
            for detection in detections:
                self.tracks.append({
                    'id': self.next_id,
                    'bbox': detection['bbox'],
                    'class_name': detection['class_name'],
                    'disappeared': 0
                })
                self.next_id += 1
        else:
            # ç®€å•çš„æœ€è¿‘é‚»åŒ¹é…
            self.match_detections(detections)
        
        # ç§»é™¤æ¶ˆå¤±å¤ªä¹…çš„è¿½è¸ª
        self.tracks = [track for track in self.tracks if track['disappeared'] < self.max_disappeared]
        
        return self.tracks
    
    def match_detections(self, detections):
        """åŒ¹é…æ£€æµ‹ç»“æžœåˆ°è¿½è¸ª"""
        for track in self.tracks:
            track['disappeared'] += 1
        
        for detection in detections:
            # æ‰¾åˆ°æœ€è¿‘çš„è¿½è¸ª
            best_match = None
            min_distance = float('inf')
            
            det_center = self.get_center(detection['bbox'])
            
            for track in self.tracks:
                if track['disappeared'] < self.max_disappeared:
                    track_center = self.get_center(track['bbox'])
                    distance = self.calculate_distance(det_center, track_center)
                    
                    if distance < min_distance and distance < 100:  # è·ç¦»é˜ˆå€¼
                        min_distance = distance
                        best_match = track
            
            if best_match:
                # æ›´æ–°è¿½è¸ª
                best_match['bbox'] = detection['bbox']
                best_match['class_name'] = detection['class_name']
                best_match['disappeared'] = 0
            else:
                # åˆ›å»ºæ–°è¿½è¸ª
                self.tracks.append({
                    'id': self.next_id,
                    'bbox': detection['bbox'],
                    'class_name': detection['class_name'],
                    'disappeared': 0
                })
                self.next_id += 1
    
    def get_center(self, bbox):
        """èŽ·å–è¾¹ç•Œæ¡†ä¸­å¿ƒç‚¹"""
        x, y, w, h = bbox
        return (x + w // 2, y + h // 2)
    
    def calculate_distance(self, point1, point2):
        """è®¡ç®—ä¸¤ç‚¹è·ç¦»"""
        return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)

def process_video(input_path, output_path=None, show_video=True):
    """å¤„ç†è§†é¢‘"""
    print("æ­£åœ¨åˆå§‹åŒ–æ£€æµ‹å™¨...")
    detector = OpenCVObjectDetector()
    tracker = SimpleTracker()
    
    # æ‰“å¼€è§†é¢‘
    cap = cv2.VideoCapture(input_path)
    
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {input_path}")
        return False
    
    # èŽ·å–è§†é¢‘å±žæ€§
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print("=" * 50)
    print("è§†é¢‘ä¿¡æ¯")
    print("=" * 50)
    print(f"åˆ†è¾¨çŽ‡: {width}x{height}")
    print(f"å¸§çŽ‡: {fps} FPS")
    print(f"æ€»å¸§æ•°: {total_frames}")
    print(f"æ—¶é•¿: {total_frames/fps:.2f} ç§’")
    print("=" * 50)
    
    # è®¾ç½®è¾“å‡ºè§†é¢‘
    if output_path:
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    frame_count = 0
    
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            
            # æ£€æµ‹ç‰©ä½“
            detections = detector.detect_objects(frame)
            
            # æ›´æ–°è¿½è¸ª
            tracks = tracker.update(detections)
            
            # è°ƒè¯•ä¿¡æ¯ï¼šè¯¦ç»†æ£€æµ‹å’Œè¿½è¸ªç»“æžœ
            if frame_count % 100 == 0 or frame_count == 1:
                active_tracks = [t for t in tracks if t['disappeared'] == 0]
                print(f"ç¬¬{frame_count}å¸§æ£€æµ‹åˆ° {len(detections)} ä¸ªç‰©ä½“ï¼Œè¿½è¸ªåˆ° {len(active_tracks)} ä¸ªç‰©ä½“")
                for i, det in enumerate(detections):
                    print(f"  æ£€æµ‹{i+1}: {det['class_name']} (ç½®ä¿¡åº¦: {det['confidence']:.2f})")
                for i, track in enumerate(active_tracks):
                    print(f"  è¿½è¸ª{i+1}: ID{track['id']} {track['class_name']}")
            
            # ç»˜åˆ¶ç»“æžœ
            annotated_frame = frame.copy()
            
            # ç›´æŽ¥ç»˜åˆ¶æ£€æµ‹ç»“æžœï¼Œè€Œä¸æ˜¯è¿½è¸ªç»“æžœï¼Œä»¥æ˜¾ç¤ºç½®ä¿¡åº¦
            for detection in detections:
                x, y, w, h = detection['bbox']
                class_name = detection['class_name']
                confidence = detection['confidence']
                
                # ç”Ÿæˆå›ºå®šé¢œè‰²ï¼ˆåŸºäºŽç±»åˆ«ï¼‰
                color_seed = hash(class_name) % 255
                np.random.seed(color_seed)
                color = tuple(map(int, np.random.randint(100, 255, 3)))
                
                # ç»˜åˆ¶è¾¹ç•Œæ¡†
                cv2.rectangle(annotated_frame, (x, y), (x + w, y + h), color, 2)
                
                # ç»˜åˆ¶ç±»åˆ«å’Œç½®ä¿¡åº¦æ ‡ç­¾
                label = f"{class_name} {confidence:.2f}"
                font_scale = 0.5  # è°ƒå°å­—ä½“
                thickness = 1
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)[0]
                
                # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯
                cv2.rectangle(annotated_frame, (x, y - label_size[1] - 8), 
                            (x + label_size[0] + 4, y), color, -1)
                
                # ç»˜åˆ¶æ–‡å­—
                cv2.putText(annotated_frame, label, (x + 2, y - 4), 
                          cv2.FONT_HERSHEY_SIMPLEX, font_scale, (255, 255, 255), thickness)
            
            # åŒæ—¶ç»˜åˆ¶è¿½è¸ªID
            for track in tracks:
                if track['disappeared'] == 0:  # åªç»˜åˆ¶å½“å‰å¸§æ£€æµ‹åˆ°çš„
                    x, y, w, h = track['bbox']
                    track_id = track['id']
                    
                    # åœ¨å³ä¸Šè§’æ˜¾ç¤ºè¿½è¸ªID
                    id_label = f"ID:{track_id}"
                    cv2.putText(annotated_frame, id_label, (x + w - 40, y + 15), 
                              cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 255, 255), 1)
            
            # æ·»åŠ ä¿¡æ¯
            cv2.putText(annotated_frame, f"Frame: {frame_count}/{total_frames}", 
                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(annotated_frame, f"Objects: {len([t for t in tracks if t['disappeared'] == 0])}", 
                    (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            
            # æ˜¾ç¤ºè§†é¢‘
            if show_video:
                cv2.imshow('Object Detection & Tracking', annotated_frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
            
            # ä¿å­˜è¾“å‡º
            if output_path:
                out.write(annotated_frame)
            
            # æ˜¾ç¤ºè¿›åº¦
            if frame_count % 30 == 0:
                progress = (frame_count / total_frames) * 100
                print(f"å¤„ç†è¿›åº¦: {progress:.1f}%")
    
    finally:
        cap.release()
        if output_path:
            out.release()
        cv2.destroyAllWindows()
    
    print(f"âœ… å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {frame_count} å¸§")
    return True

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è§†é¢‘ä¸­ç§»åŠ¨ç‰©ä½“é€Ÿåº¦ä¼°è®¡ - OpenCVç‰ˆæœ¬')
    parser.add_argument('--input', '-i', required=True, help='è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', default='output_opencv.mp4', help='è¾“å‡ºè§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--no-display', action='store_true', help='ä¸æ˜¾ç¤ºè§†é¢‘çª—å£')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return
    
    print("ðŸš€ å¼€å§‹å¤„ç†è§†é¢‘...")
    success = process_video(
        input_path=args.input,
        output_path=args.output,
        show_video=not args.no_display
    )
    
    if success:
        print("\n" + "=" * 50)
        print("ðŸŽ‰ OpenCVç‰ˆæœ¬å¤„ç†å®Œæˆï¼")
        print("âœ… ç‰©ä½“æ£€æµ‹åŠŸèƒ½æ­£å¸¸")
        print("âœ… ç‰©ä½“è¿½è¸ªåŠŸèƒ½æ­£å¸¸")
        print("âœ… è§†é¢‘å¸§æ•°æ£€æµ‹åŠŸèƒ½æ­£å¸¸")
        print(f"âœ… è¾“å‡ºæ–‡ä»¶: {args.output}")
        print("=" * 50)

if __name__ == "__main__":
    main()
