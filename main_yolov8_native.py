"""
YOLOv8åŸç”Ÿç‰ˆæœ¬ - ä½¿ç”¨ultralyticsåº“
æ›´å‡†ç¡®çš„æ£€æµ‹ç»“æœå’Œæ›´å¥½çš„æ€§èƒ½
"""
import cv2
import numpy as np
import os
import argparse
import sys
from ultralytics import YOLO

class YOLOv8Detector:
    def __init__(self, model_name='yolov8n.pt'):
        """åˆå§‹åŒ–YOLOv8æ£€æµ‹å™¨"""
        self.model_name = f"models/{model_name}"  # ä»modelsæ–‡ä»¶å¤¹åŠ è½½
        self.model = None
        self.setup_model()
        
    def setup_model(self):
        """è®¾ç½®YOLOv8æ¨¡å‹"""
        try:
            # ç¡®ä¿modelsç›®å½•å­˜åœ¨
            os.makedirs('models', exist_ok=True)
            
            print(f"æ­£åœ¨åŠ è½½YOLOv8æ¨¡å‹: {self.model_name}")
            
            # å¦‚æœæ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä¼šè‡ªåŠ¨ä¸‹è½½åˆ°æŒ‡å®šä½ç½®
            if not os.path.exists(self.model_name):
                print(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†è‡ªåŠ¨ä¸‹è½½åˆ°: {self.model_name}")
                # å…ˆåŠ è½½åˆ°å½“å‰ç›®å½•ï¼Œç„¶åç§»åŠ¨åˆ°modelsæ–‡ä»¶å¤¹
                temp_model = YOLO('yolov8n.pt')
                temp_model.save(self.model_name)
                self.model = YOLO(self.model_name)
            else:
                self.model = YOLO(self.model_name)
                
            print("âœ… YOLOv8åŸç”Ÿæ¨¡å‹åŠ è½½æˆåŠŸ")
            
            # è·å–ç±»åˆ«åç§°
            self.classes = list(self.model.names.values())
            print(f"ğŸ“ åŠ è½½äº† {len(self.classes)} ä¸ªç‰©ä½“ç±»åˆ«")
            
        except Exception as e:
            print(f"âŒ YOLOv8æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            print("å°è¯•ä»é»˜è®¤ä½ç½®åŠ è½½...")
            try:
                self.model = YOLO('yolov8n.pt')
                self.classes = list(self.model.names.values())
                print("âœ… ä½¿ç”¨é»˜è®¤ä½ç½®çš„æ¨¡å‹åŠ è½½æˆåŠŸ")
            except Exception as e2:
                print(f"âŒ å®Œå…¨åŠ è½½å¤±è´¥: {e2}")
                sys.exit(1)
    
    def detect_objects(self, frame, conf_threshold=0.25):
        """é’ˆå¯¹å•å¸§å›¾åƒæ£€æµ‹ç‰©ä½“"""
        try:
            # ä½¿ç”¨YOLOv8è¿›è¡Œæ£€æµ‹
            results = self.model(frame, verbose=False, conf=conf_threshold, iou=0.4)
            
            detections = []
            if results and len(results) > 0:
                for result in results:
                    if result.boxes is not None:
                        boxes = result.boxes
                        
                        # æå–æ£€æµ‹ç»“æœ
                        for i in range(len(boxes)):
                            # è·å–è¾¹ç•Œæ¡†åæ ‡ (xyxyæ ¼å¼)
                            x1, y1, x2, y2 = boxes.xyxy[i].cpu().numpy()
                            
                            # è½¬æ¢ä¸ºxywhæ ¼å¼
                            x = int(x1)
                            y = int(y1)
                            w = int(x2 - x1)
                            h = int(y2 - y1)
                            
                            # è·å–ç½®ä¿¡åº¦å’Œç±»åˆ«ID
                            confidence = float(boxes.conf[i].cpu().numpy())
                            class_id = int(boxes.cls[i].cpu().numpy())
                            
                            # ä½¿ç”¨ä¼ å…¥çš„ç½®ä¿¡åº¦é˜ˆå€¼
                            if confidence >= conf_threshold:
                                class_name = self.classes[class_id] if class_id < len(self.classes) else 'unknown'
                                
                                detections.append({
                                    'bbox': [x, y, w, h],
                                    'confidence': confidence,
                                    'class_id': class_id,
                                    'class_name': class_name
                                })
            
            return detections
            
        except Exception as e:
            print(f"æ£€æµ‹è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            return []

class SimpleTracker:
    def __init__(self):
        """ç®€å•çš„ç‰©ä½“è¿½è¸ªå™¨"""
        self.tracks = []      # å½“å‰è¿½è¸ªåˆ—è¡¨
        self.next_id = 1    # ä¸‹ä¸€ä¸ªIDç”Ÿæˆå™¨
        self.max_disappeared = 30 # æœ€å¤§å®¹å¿æ¶ˆå¤±å¸§æ•°
    
    #ä¼šè°ƒç”¨YOLOæ£€æµ‹åˆ°çš„detection
    def update(self, detections):
        """æ›´æ–°è¿½è¸ª"""
        if len(self.tracks) == 0:
            # æƒ…å†µ1: é¦–æ¬¡æ£€æµ‹ï¼Œåˆå§‹åŒ–è¿½è¸ª
            for detection in detections:
                self.tracks.append({
                    'id': self.next_id,
                    'bbox': detection['bbox'],  # æœ€åå·²çŸ¥ä½ç½®
                    'class_name': detection['class_name'],  # ç±»åˆ«
                    'disappeared': 0 #æ¶ˆå¤±è®¡æ•°å™¨ï¼Œç”¨æ¥å¤„ç†ç‰©ä½“æš‚æ—¶æ¶ˆå¤±çš„æƒ…å†µ
                })
                self.next_id += 1
        else:
            # æƒ…å†µ2: ç°æœ‰è¿½è¸ªï¼Œè¿›è¡Œæœ€è¿‘é‚»åŒ¹é…
            self.match_detections(detections)
        
        # ç§»é™¤æ¶ˆå¤±å¤ªä¹…çš„è¿½è¸ª
        self.tracks = [track for track in self.tracks 
                    if track['disappeared'] < self.max_disappeared] 
        
        return self.tracks
    
    def match_detections(self, detections):
        """åŒ¹é…æ£€æµ‹ç»“æœåˆ°è¿½è¸ª"""
        # æ­¥éª¤1: æ‰€æœ‰è¿½è¸ªçš„æ¶ˆå¤±è®¡æ•°+1
        for track in self.tracks:
            track['disappeared'] += 1
        
        # æ­¥éª¤2: ä¸ºæ¯ä¸ªæ–°æ£€æµ‹æ‰¾æœ€ä½³åŒ¹é…
        for detection in detections:
            # æ‰¾åˆ°æœ€è¿‘çš„è¿½è¸ª
            best_match = None
            min_distance = float('inf')
            det_center = self.get_center(detection['bbox'])
            
            # è®¡ç®—ä¸æ‰€æœ‰è¿½è¸ªçš„è·ç¦»
            for track in self.tracks:
                if track['disappeared'] < self.max_disappeared:
                    track_center = self.get_center(track['bbox'])
                    distance = self.calculate_distance(det_center, track_center)
                    
                    # æ‰¾æœ€è¿‘ä¸”è·ç¦»<100åƒç´ çš„è¿½è¸ª
                    if distance < min_distance and distance < 100:  # è·ç¦»é˜ˆå€¼
                        min_distance = distance
                        best_match = track
            
            if best_match:
                # æ‰¾åˆ°åŒ¹é…ï¼šæ›´æ–°è¿½è¸ª
                best_match['bbox'] = detection['bbox']
                best_match['class_name'] = detection['class_name']
                best_match['disappeared'] = 0 # æ‰¾åˆ°äº†ï¼Œå……å€¼æ¶ˆå¤±è®¡æ•°å™¨
            else:
                # æ²¡æ‰¾åˆ°åŒ¹é…ï¼šåˆ›å»ºæ–°è¿½è¸ª
                self.tracks.append({
                    'id': self.next_id,
                    'bbox': detection['bbox'],
                    'class_name': detection['class_name'],
                    'disappeared': 0
                })
                self.next_id += 1
    
    def get_center(self, bbox):
        """è·å–è¾¹ç•Œæ¡†ä¸­å¿ƒç‚¹"""
        x, y, w, h = bbox
        return (x + w // 2, y + h // 2)
    
    def calculate_distance(self, point1, point2):
        """è®¡ç®—ä¸¤ç‚¹è·ç¦»"""
        return np.sqrt((point1[0] - point2[0])**2 + (point1[1] - point2[1])**2)

def process_video(input_path, output_path=None, show_video=True, conf_threshold=0.25):
    """å¤„ç†è§†é¢‘"""
    print("æ­£åœ¨åˆå§‹åŒ–YOLOv8æ£€æµ‹å™¨...")
    detector = YOLOv8Detector('yolov8n.pt')  # ä½¿ç”¨nanoç‰ˆæœ¬ï¼Œé€Ÿåº¦å¿«
    tracker = SimpleTracker()
    
    print(f"ä½¿ç”¨ç½®ä¿¡åº¦é˜ˆå€¼: {conf_threshold}")
    if conf_threshold < 0.1:
        print("âš ï¸  æ³¨æ„ï¼šä½¿ç”¨ä½ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œå¯èƒ½æ£€æµ‹åˆ°è¾ƒå¤šè¯¯æŠ¥")
    
    # æ‰“å¼€è§†é¢‘
    cap = cv2.VideoCapture(input_path)
    
    if not cap.isOpened():
        print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {input_path}")
        return False
    
    # è·å–è§†é¢‘å±æ€§
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    
    print("=" * 50)
    print("è§†é¢‘ä¿¡æ¯")
    print("=" * 50)
    print(f"åˆ†è¾¨ç‡: {width}x{height}")
    print(f"å¸§ç‡: {fps} FPS")
    print(f"æ€»å¸§æ•°: {total_frames}")
    print(f"æ—¶é•¿: {total_frames/fps:.2f} ç§’")
    print("=" * 50)
    
    # è®¾ç½®è¾“å‡ºè§†é¢‘
    if output_path:
        fourcc = cv2.VideoWriter_fourcc(*'mp4v')
        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))
    
    frame_count = 0
    
    #é€å¸§å¤„ç†çš„ä¸»å¾ªç¯
    try:
        while True:
            ret, frame = cap.read()
            if not ret:
                break
            
            frame_count += 1
            
            # æ£€æµ‹ç‰©ä½“
            detections = detector.detect_objects(frame, conf_threshold)
            
            # æ›´æ–°è¿½è¸ª
            tracks = tracker.update(detections)
            
            # è°ƒè¯•ä¿¡æ¯ï¼šè¯¦ç»†æ£€æµ‹å’Œè¿½è¸ªç»“æœ
            if frame_count % 100 == 0 or frame_count == 1:
                active_tracks = [t for t in tracks if t['disappeared'] == 0]
                print(f"ç¬¬{frame_count}å¸§æ£€æµ‹åˆ° {len(detections)} ä¸ªç‰©ä½“ï¼Œè¿½è¸ªåˆ° {len(active_tracks)} ä¸ªç‰©ä½“")
                
                # è°ƒè¯•ï¼šæ‰“å°åŸå§‹æ£€æµ‹ç»“æœ
                raw_results = detector.model(frame, verbose=False, conf=0.01, iou=0.5)  # æä½é˜ˆå€¼ç”¨äºè°ƒè¯•
                if raw_results and len(raw_results) > 0:
                    for result in raw_results:
                        if result.boxes is not None:
                            print(f"  åŸå§‹æ£€æµ‹æ•°é‡: {len(result.boxes)}")
                            if len(result.boxes) > 0:
                                max_conf = float(result.boxes.conf.max())
                                print(f"  æœ€é«˜ç½®ä¿¡åº¦: {max_conf:.4f}")
                
                for i, det in enumerate(detections):
                    print(f"  æ£€æµ‹{i+1}: {det['class_name']} (ç½®ä¿¡åº¦: {det['confidence']:.3f})")
                for i, track in enumerate(active_tracks):
                    print(f"  è¿½è¸ª{i+1}: ID{track['id']} {track['class_name']}")
            
            # ç»˜åˆ¶ç»“æœ
            annotated_frame = frame.copy()
            
            # ç»˜åˆ¶æ£€æµ‹ç»“æœï¼Œæ˜¾ç¤ºç±»åˆ«å’Œç½®ä¿¡åº¦
            for i, detection in enumerate(detections):
                x, y, w, h = detection['bbox']
                class_name = detection['class_name']
                confidence = detection['confidence']
                
                # ç”Ÿæˆæ›´å¥½çœ‹çš„é¢œè‰²ï¼ˆåŸºäºç±»åˆ«ï¼Œä½†ç¡®ä¿ä¸ä¼šå¤ªæš—ï¼‰
                color_seed = hash(class_name) % 255
                np.random.seed(color_seed)
                # ç¡®ä¿é¢œè‰²æ˜äº®ä¸”å¯¹æ¯”åº¦é«˜
                base_colors = [
                    (255, 0, 0), (0, 255, 0), (0, 0, 255),     # çº¢ç»¿è“
                    (255, 255, 0), (255, 0, 255), (0, 255, 255), # é’å“é»„
                    (255, 128, 0), (255, 0, 128), (128, 255, 0), # æ©™è‰²ç³»
                    (0, 128, 255), (128, 0, 255), (255, 128, 128) # å…¶ä»–
                ]
                color = base_colors[color_seed % len(base_colors)]
                
                # ç»˜åˆ¶è¾¹ç•Œæ¡†ï¼ˆåŠ ç²—ä¸€ç‚¹ï¼‰
                cv2.rectangle(annotated_frame, (x, y), (x + w, y + h), color, 3)
                
                # ç»˜åˆ¶ç±»åˆ«å’Œç½®ä¿¡åº¦æ ‡ç­¾
                label = f"{class_name} {confidence:.3f}"
                font_scale = 0.6  # ç¨å¾®å¤§ä¸€ç‚¹çš„å­—ä½“
                thickness = 2
                label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)[0]
                
                # ç»˜åˆ¶æ ‡ç­¾èƒŒæ™¯ï¼ˆç¨å¾®å¤§ä¸€ç‚¹çš„èƒŒæ™¯ï¼‰
                bg_x1 = x
                bg_y1 = y - label_size[1] - 12
                bg_x2 = x + label_size[0] + 8
                bg_y2 = y - 2
                
                # ç¡®ä¿èƒŒæ™¯åœ¨å›¾åƒèŒƒå›´å†…
                bg_y1 = max(0, bg_y1)
                
                # ç»˜åˆ¶åŠé€æ˜èƒŒæ™¯
                overlay = annotated_frame.copy()
                cv2.rectangle(overlay, (bg_x1, bg_y1), (bg_x2, bg_y2), color, -1)
                cv2.addWeighted(overlay, 0.7, annotated_frame, 0.3, 0, annotated_frame)
                
                # ç»˜åˆ¶è¾¹æ¡†
                cv2.rectangle(annotated_frame, (bg_x1, bg_y1), (bg_x2, bg_y2), color, 2)
                
                # ç»˜åˆ¶æ–‡å­—ï¼ˆä½¿ç”¨ç™½è‰²ç¡®ä¿å¯è§æ€§ï¼‰
                text_color = (255, 255, 255)  # çº¯ç™½è‰²æ–‡å­—
                cv2.putText(annotated_frame, label, (x + 4, y - 6), 
                        cv2.FONT_HERSHEY_SIMPLEX, font_scale, text_color, thickness)
            
            # ç»˜åˆ¶è¿½è¸ªIDï¼ˆæ›´ç¾è§‚çš„æ–¹å¼ï¼‰
            for track in tracks:
                if track['disappeared'] == 0:  # åªç»˜åˆ¶å½“å‰å¸§æ£€æµ‹åˆ°çš„
                    x, y, w, h = track['bbox']
                    track_id = track['id']
                    class_name = track['class_name']
                    
                    # ç”ŸæˆIDä¸“ç”¨é¢œè‰²ï¼ˆåŸºäºIDå·ï¼‰
                    id_color_seed = track_id % 6
                    id_colors = [
                        (255, 255, 0),   # é»„è‰²
                        (0, 255, 255),   # é’è‰²
                        (255, 0, 255),   # å“çº¢
                        (255, 128, 0),   # æ©™è‰²
                        (128, 255, 0),   # è‰ç»¿
                        (0, 128, 255)    # å¤©è“
                    ]
                    id_color = id_colors[id_color_seed]
                    
                    # åœ¨å³ä¸Šè§’æ˜¾ç¤ºè¿½è¸ªID
                    id_label = f"ID{track_id}"
                    id_font_scale = 0.5
                    id_thickness = 2
                    id_label_size = cv2.getTextSize(id_label, cv2.FONT_HERSHEY_SIMPLEX, id_font_scale, id_thickness)[0]
                    
                    # IDæ ‡ç­¾ä½ç½®ï¼ˆå³ä¸Šè§’ï¼‰
                    id_x = x + w - id_label_size[0] - 8
                    id_y = y + id_label_size[1] + 8
                    
                    # ç»˜åˆ¶IDèƒŒæ™¯
                    id_bg_x1 = id_x - 4
                    id_bg_y1 = id_y - id_label_size[1] - 4
                    id_bg_x2 = id_x + id_label_size[0] + 4
                    id_bg_y2 = id_y + 4
                    
                    # åŠé€æ˜IDèƒŒæ™¯
                    id_overlay = annotated_frame.copy()
                    cv2.rectangle(id_overlay, (id_bg_x1, id_bg_y1), (id_bg_x2, id_bg_y2), id_color, -1)
                    cv2.addWeighted(id_overlay, 0.8, annotated_frame, 0.2, 0, annotated_frame)
                    
                    # IDè¾¹æ¡†
                    cv2.rectangle(annotated_frame, (id_bg_x1, id_bg_y1), (id_bg_x2, id_bg_y2), id_color, 1)
                    
                    # ç»˜åˆ¶IDæ–‡å­—ï¼ˆé»‘è‰²æ–‡å­—åœ¨äº®è‰²èƒŒæ™¯ä¸Šï¼‰
                    cv2.putText(annotated_frame, id_label, (id_x, id_y - 2), 
                            cv2.FONT_HERSHEY_SIMPLEX, id_font_scale, (0, 0, 0), id_thickness)
            
            # æ·»åŠ ä¿¡æ¯
            cv2.putText(annotated_frame, f"Frame: {frame_count}/{total_frames}", 
                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            cv2.putText(annotated_frame, f"Objects: {len([t for t in tracks if t['disappeared'] == 0])}", 
                    (10, 70), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)
            
            # æ˜¾ç¤ºè§†é¢‘
            if show_video:
                cv2.imshow('YOLOv8 Object Detection & Tracking', annotated_frame)
                if cv2.waitKey(1) & 0xFF == ord('q'):
                    break
            
            # ä¿å­˜è¾“å‡º
            if output_path:
                out.write(annotated_frame)
            
            # æ˜¾ç¤ºè¿›åº¦
            if frame_count % 30 == 0:
                progress = (frame_count / total_frames) * 100
                print(f"å¤„ç†è¿›åº¦: {progress:.1f}%")
    
    finally:
        cap.release()
        if output_path:
            out.release()
        cv2.destroyAllWindows()
    
    print(f"âœ… å¤„ç†å®Œæˆï¼Œå…±å¤„ç† {frame_count} å¸§")
    return True

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è§†é¢‘ä¸­ç§»åŠ¨ç‰©ä½“é€Ÿåº¦ä¼°è®¡ - YOLOv8åŸç”Ÿç‰ˆæœ¬')
    parser.add_argument('--input', '-i', required=True, help='è¾“å…¥è§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--output', '-o', default='output_yolov8_native.mp4', help='è¾“å‡ºè§†é¢‘æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--no-display', action='store_true', help='ä¸æ˜¾ç¤ºè§†é¢‘çª—å£')
    parser.add_argument('--model', '-m', default='yolov8n.pt', help='YOLOv8æ¨¡å‹ (yolov8n.pt, yolov8s.pt, yolov8m.pt, yolov8l.pt, yolov8x.pt)')
    parser.add_argument('--conf', '-c', type=float, default=0.25, help='ç½®ä¿¡åº¦é˜ˆå€¼ (0.01-0.9, é»˜è®¤0.25)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input):
        print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {args.input}")
        return
    
    print("å¼€å§‹å¤„ç†è§†é¢‘...")
    print(f"ä½¿ç”¨æ¨¡å‹: {args.model}")
    
    success = process_video(
        input_path=args.input,
        output_path=args.output,
        show_video=not args.no_display,
        conf_threshold=args.conf
    )
    
    if success:
        print("\n" + "=" * 50)
        print("ğŸ‰ YOLOv8åŸç”Ÿç‰ˆæœ¬å¤„ç†å®Œæˆï¼")
        print("âœ… ä½¿ç”¨ultralyticsåŸç”ŸYOLOv8")
        print("âœ… æ›´å‡†ç¡®çš„ç‰©ä½“æ£€æµ‹")
        print("âœ… æ›´ä¸°å¯Œçš„æ¨¡å‹é€‰æ‹©")
        print(f"âœ… è¾“å‡ºæ–‡ä»¶: {args.output}")
        print("=" * 50)

if __name__ == "__main__":
    main()
